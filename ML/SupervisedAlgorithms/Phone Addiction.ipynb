{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ebf9d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, r2_score, accuracy_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "07ce3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "global_phonee_addiction_data = pd.read_csv(r\"C:\\Users\\Wahaj Sajid\\Desktop\\Datasets\\mobile_addiction_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288af45b",
   "metadata": {},
   "source": [
    "# Training the model with maximum features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "3329d991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Daily_Screen_Time_Hours</th>\n",
       "      <th>Phone_Unlocks_Per_Day</th>\n",
       "      <th>Social_Media_Usage_Hours</th>\n",
       "      <th>Gaming_Usage_Hours</th>\n",
       "      <th>Streaming_Usage_Hours</th>\n",
       "      <th>Messaging_Usage_Hours</th>\n",
       "      <th>Work_Related_Usage_Hours</th>\n",
       "      <th>Sleep_Hours</th>\n",
       "      <th>Physical_Activity_Hours</th>\n",
       "      <th>Mental_Health_Score</th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Time_Spent_With_Family_Hours</th>\n",
       "      <th>Online_Shopping_Hours</th>\n",
       "      <th>Has_Screen_Time_Management_App</th>\n",
       "      <th>Self_Reported_Addiction_Level</th>\n",
       "      <th>Monthly_Data_Usage_GB</th>\n",
       "      <th>Age_First_Phone</th>\n",
       "      <th>Push_Notifications_Per_Day</th>\n",
       "      <th>Tech_Savviness_Score</th>\n",
       "      <th>Education_Level_Bachelor's</th>\n",
       "      <th>Education_Level_High School</th>\n",
       "      <th>Education_Level_Master's</th>\n",
       "      <th>Education_Level_PhD</th>\n",
       "      <th>Internet_Connection_Type_3G</th>\n",
       "      <th>Internet_Connection_Type_4G</th>\n",
       "      <th>Internet_Connection_Type_5G</th>\n",
       "      <th>Internet_Connection_Type_WiFi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.545901</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.087332</td>\n",
       "      <td>-0.187150</td>\n",
       "      <td>-1.226895</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>1.408563</td>\n",
       "      <td>-0.097239</td>\n",
       "      <td>0.137444</td>\n",
       "      <td>-1.281268</td>\n",
       "      <td>0.655975</td>\n",
       "      <td>0.397611</td>\n",
       "      <td>1.050254</td>\n",
       "      <td>-0.902258</td>\n",
       "      <td>1.623854</td>\n",
       "      <td>0.296190</td>\n",
       "      <td>2.245840</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.875498</td>\n",
       "      <td>0.547706</td>\n",
       "      <td>0.228847</td>\n",
       "      <td>-0.350145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.897817</td>\n",
       "      <td>1</td>\n",
       "      <td>1.521798</td>\n",
       "      <td>-0.744105</td>\n",
       "      <td>1.185212</td>\n",
       "      <td>1.061118</td>\n",
       "      <td>-1.244840</td>\n",
       "      <td>1.831661</td>\n",
       "      <td>-0.607396</td>\n",
       "      <td>-0.264479</td>\n",
       "      <td>-0.727408</td>\n",
       "      <td>1.603153</td>\n",
       "      <td>1.677514</td>\n",
       "      <td>-0.351238</td>\n",
       "      <td>-0.851988</td>\n",
       "      <td>-0.757133</td>\n",
       "      <td>-0.340657</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.821476</td>\n",
       "      <td>-0.523078</td>\n",
       "      <td>0.394190</td>\n",
       "      <td>-1.387322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.682903</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.112164</td>\n",
       "      <td>-0.863452</td>\n",
       "      <td>0.121357</td>\n",
       "      <td>0.457874</td>\n",
       "      <td>-0.166895</td>\n",
       "      <td>0.965624</td>\n",
       "      <td>-0.096648</td>\n",
       "      <td>0.077806</td>\n",
       "      <td>1.934556</td>\n",
       "      <td>0.822544</td>\n",
       "      <td>-0.196679</td>\n",
       "      <td>1.534281</td>\n",
       "      <td>1.754695</td>\n",
       "      <td>0.283023</td>\n",
       "      <td>-1.470891</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.262012</td>\n",
       "      <td>1.083098</td>\n",
       "      <td>-0.300253</td>\n",
       "      <td>0.028177</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157932</td>\n",
       "      <td>0</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>-0.426371</td>\n",
       "      <td>1.284542</td>\n",
       "      <td>-0.104706</td>\n",
       "      <td>1.851343</td>\n",
       "      <td>-0.203054</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>-0.140518</td>\n",
       "      <td>0.117455</td>\n",
       "      <td>-1.360506</td>\n",
       "      <td>-1.545918</td>\n",
       "      <td>0.598463</td>\n",
       "      <td>-0.480636</td>\n",
       "      <td>-1.405685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.612967</td>\n",
       "      <td>0.815402</td>\n",
       "      <td>-1.292315</td>\n",
       "      <td>-0.646283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275238</td>\n",
       "      <td>2</td>\n",
       "      <td>0.160991</td>\n",
       "      <td>2.239581</td>\n",
       "      <td>-0.521170</td>\n",
       "      <td>0.200936</td>\n",
       "      <td>-0.540030</td>\n",
       "      <td>-0.372796</td>\n",
       "      <td>-0.266898</td>\n",
       "      <td>-1.069856</td>\n",
       "      <td>0.069085</td>\n",
       "      <td>0.590414</td>\n",
       "      <td>-0.441513</td>\n",
       "      <td>-1.123699</td>\n",
       "      <td>-1.212677</td>\n",
       "      <td>-0.546468</td>\n",
       "      <td>-0.514539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.499993</td>\n",
       "      <td>1.083098</td>\n",
       "      <td>0.923290</td>\n",
       "      <td>-0.962534</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender  ...  Internet_Connection_Type_5G  Internet_Connection_Type_WiFi\n",
       "0 -0.545901       1  ...                            1                              0\n",
       "1 -0.897817       1  ...                            0                              0\n",
       "2  1.682903       2  ...                            0                              1\n",
       "3  0.157932       0  ...                            0                              0\n",
       "4  0.275238       2  ...                            0                              0\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_phonee_addiction_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "18d3f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_phonee_addiction_data = global_phonee_addiction_data.drop(columns=['User_ID', 'Country', 'Occupation','Income_USD','Relationship_Status','Has_Children','Urban_or_Rural','Primary_Device_Brand','Has_Night_Mode_On'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "607dc902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 25)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_phonee_addiction_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "5770113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                               0\n",
       "Gender                            0\n",
       "Education_Level                   0\n",
       "Daily_Screen_Time_Hours           0\n",
       "Phone_Unlocks_Per_Day             0\n",
       "Social_Media_Usage_Hours          0\n",
       "Gaming_Usage_Hours                0\n",
       "Streaming_Usage_Hours             0\n",
       "Messaging_Usage_Hours             0\n",
       "Work_Related_Usage_Hours          0\n",
       "Sleep_Hours                       0\n",
       "Physical_Activity_Hours           0\n",
       "Mental_Health_Score               0\n",
       "Depression_Score                  0\n",
       "Anxiety_Score                     0\n",
       "Stress_Level                      0\n",
       "Time_Spent_With_Family_Hours      0\n",
       "Online_Shopping_Hours             0\n",
       "Internet_Connection_Type          0\n",
       "Has_Screen_Time_Management_App    0\n",
       "Self_Reported_Addiction_Level     0\n",
       "Monthly_Data_Usage_GB             0\n",
       "Age_First_Phone                   0\n",
       "Push_Notifications_Per_Day        0\n",
       "Tech_Savviness_Score              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_phonee_addiction_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "6f0bf666",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_phonee_addiction_data['Education_Level'] = global_phonee_addiction_data['Education_Level'].fillna(global_phonee_addiction_data['Education_Level'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "da263e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_phonee_addiction_data = pd.get_dummies(global_phonee_addiction_data, columns=['Education_Level','Internet_Connection_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "35096884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Wahaj Sajid\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#encode the categorical data \n",
    "encoder =  LabelEncoder()\n",
    "\n",
    "non_numeric_columns = global_phonee_addiction_data.select_dtypes(exclude='number')\n",
    "\n",
    "\n",
    "for column in non_numeric_columns.columns:\n",
    "    global_phonee_addiction_data[column] = encoder.fit_transform(global_phonee_addiction_data[[column]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "e95d9f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 0\n",
      "Daily_Screen_Time_Hours 0\n",
      "Phone_Unlocks_Per_Day 0\n",
      "Social_Media_Usage_Hours 0\n",
      "Gaming_Usage_Hours 0\n",
      "Streaming_Usage_Hours 0\n",
      "Messaging_Usage_Hours 0\n",
      "Work_Related_Usage_Hours 0\n",
      "Sleep_Hours 0\n",
      "Physical_Activity_Hours 0\n",
      "Mental_Health_Score 0\n",
      "Depression_Score 0\n",
      "Anxiety_Score 0\n",
      "Stress_Level 0\n",
      "Time_Spent_With_Family_Hours 0\n",
      "Online_Shopping_Hours 0\n",
      "Monthly_Data_Usage_GB 0\n",
      "Age_First_Phone 0\n",
      "Push_Notifications_Per_Day 0\n",
      "Tech_Savviness_Score 0\n"
     ]
    }
   ],
   "source": [
    "#check for the negative values\n",
    "\n",
    "numeric_data = global_phonee_addiction_data.select_dtypes(exclude=['object', 'bool'])\n",
    "\n",
    "for column in numeric_data.columns:\n",
    "    print(column, len(global_phonee_addiction_data[column][global_phonee_addiction_data[column] < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "039bc177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the negative values to positive values\n",
    "numeric_data1 = global_phonee_addiction_data.select_dtypes(exclude=['object', 'bool'])\n",
    "\n",
    "global_phonee_addiction_data[numeric_data1.columns] = global_phonee_addiction_data[numeric_data1.columns].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "ec3d2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_columns = global_phonee_addiction_data.select_dtypes(exclude=['object', 'bool'])\n",
    "\n",
    "\n",
    "\n",
    "for column in numeric_columns.columns:\n",
    "     global_phonee_addiction_data[column] = scaler.fit_transform(global_phonee_addiction_data[[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "770afb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining x and y\n",
    "x = global_phonee_addiction_data.drop(columns=['Self_Reported_Addiction_Level'], axis=1)\n",
    "y = global_phonee_addiction_data['Self_Reported_Addiction_Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "b43b1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tain test split the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "c09a02e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2300 - loss: 1.4666 - val_accuracy: 0.2583 - val_loss: 1.4102\n",
      "Epoch 2/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2497 - loss: 1.4058 - val_accuracy: 0.2562 - val_loss: 1.4011\n",
      "Epoch 3/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2873 - loss: 1.3833 - val_accuracy: 0.2604 - val_loss: 1.4009\n",
      "Epoch 4/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2929 - loss: 1.3807 - val_accuracy: 0.2625 - val_loss: 1.4018\n",
      "Epoch 5/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3240 - loss: 1.3633 - val_accuracy: 0.2562 - val_loss: 1.4036\n",
      "Epoch 6/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3168 - loss: 1.3573 - val_accuracy: 0.2604 - val_loss: 1.4031\n",
      "Epoch 7/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3511 - loss: 1.3518 - val_accuracy: 0.2646 - val_loss: 1.4049\n",
      "Epoch 8/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3587 - loss: 1.3484 - val_accuracy: 0.2667 - val_loss: 1.4078\n",
      "Epoch 9/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3577 - loss: 1.3402 - val_accuracy: 0.2646 - val_loss: 1.4087\n",
      "Epoch 10/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3802 - loss: 1.3331 - val_accuracy: 0.2729 - val_loss: 1.4117\n",
      "Epoch 11/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3580 - loss: 1.3380 - val_accuracy: 0.2479 - val_loss: 1.4141\n",
      "Epoch 12/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3822 - loss: 1.3226 - val_accuracy: 0.2562 - val_loss: 1.4172\n",
      "Epoch 13/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3948 - loss: 1.3132 - val_accuracy: 0.2583 - val_loss: 1.4220\n",
      "Epoch 14/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3968 - loss: 1.3081 - val_accuracy: 0.2583 - val_loss: 1.4213\n",
      "Epoch 15/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3993 - loss: 1.2990 - val_accuracy: 0.2625 - val_loss: 1.4298\n",
      "Epoch 16/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4303 - loss: 1.2837 - val_accuracy: 0.2479 - val_loss: 1.4287\n",
      "Epoch 17/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4155 - loss: 1.2843 - val_accuracy: 0.2458 - val_loss: 1.4355\n",
      "Epoch 18/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4411 - loss: 1.2643 - val_accuracy: 0.2438 - val_loss: 1.4417\n",
      "Epoch 19/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4356 - loss: 1.2614 - val_accuracy: 0.2604 - val_loss: 1.4446\n",
      "Epoch 20/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4324 - loss: 1.2539 - val_accuracy: 0.2396 - val_loss: 1.4543\n",
      "Epoch 21/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4456 - loss: 1.2532 - val_accuracy: 0.2354 - val_loss: 1.4605\n",
      "Epoch 22/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4382 - loss: 1.2457 - val_accuracy: 0.2458 - val_loss: 1.4693\n",
      "Epoch 23/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4335 - loss: 1.2408 - val_accuracy: 0.2333 - val_loss: 1.4754\n",
      "Epoch 24/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4688 - loss: 1.2210 - val_accuracy: 0.2292 - val_loss: 1.4880\n",
      "Epoch 25/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4449 - loss: 1.2210 - val_accuracy: 0.2333 - val_loss: 1.4892\n",
      "Epoch 26/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4693 - loss: 1.2131 - val_accuracy: 0.2333 - val_loss: 1.4981\n",
      "Epoch 27/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4760 - loss: 1.1992 - val_accuracy: 0.2354 - val_loss: 1.5099\n",
      "Epoch 28/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4765 - loss: 1.1907 - val_accuracy: 0.2271 - val_loss: 1.5187\n",
      "Epoch 29/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4889 - loss: 1.1824 - val_accuracy: 0.2354 - val_loss: 1.5238\n",
      "Epoch 30/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4881 - loss: 1.1835 - val_accuracy: 0.2354 - val_loss: 1.5284\n",
      "Epoch 31/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4953 - loss: 1.1667 - val_accuracy: 0.2229 - val_loss: 1.5391\n",
      "Epoch 32/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5055 - loss: 1.1518 - val_accuracy: 0.2417 - val_loss: 1.5459\n",
      "Epoch 33/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4942 - loss: 1.1500 - val_accuracy: 0.2313 - val_loss: 1.5520\n",
      "Epoch 34/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4731 - loss: 1.1692 - val_accuracy: 0.2250 - val_loss: 1.5590\n",
      "Epoch 35/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4866 - loss: 1.1509 - val_accuracy: 0.2333 - val_loss: 1.5652\n",
      "Epoch 36/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5136 - loss: 1.1295 - val_accuracy: 0.2292 - val_loss: 1.5818\n",
      "Epoch 37/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4954 - loss: 1.1416 - val_accuracy: 0.2271 - val_loss: 1.5825\n",
      "Epoch 38/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5262 - loss: 1.1228 - val_accuracy: 0.2313 - val_loss: 1.5893\n",
      "Epoch 39/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5167 - loss: 1.1244 - val_accuracy: 0.2438 - val_loss: 1.6039\n",
      "Epoch 40/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5139 - loss: 1.1221 - val_accuracy: 0.2292 - val_loss: 1.6147\n",
      "Epoch 41/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5172 - loss: 1.1082 - val_accuracy: 0.2229 - val_loss: 1.6130\n",
      "Epoch 42/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5282 - loss: 1.1082 - val_accuracy: 0.2354 - val_loss: 1.6213\n",
      "Epoch 43/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5212 - loss: 1.0975 - val_accuracy: 0.2333 - val_loss: 1.6299\n",
      "Epoch 44/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5349 - loss: 1.0897 - val_accuracy: 0.2313 - val_loss: 1.6371\n",
      "Epoch 45/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5364 - loss: 1.0799 - val_accuracy: 0.2417 - val_loss: 1.6445\n",
      "Epoch 46/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5238 - loss: 1.0872 - val_accuracy: 0.2229 - val_loss: 1.6567\n",
      "Epoch 47/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5348 - loss: 1.0807 - val_accuracy: 0.2313 - val_loss: 1.6635\n",
      "Epoch 48/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5425 - loss: 1.0706 - val_accuracy: 0.2417 - val_loss: 1.6736\n",
      "Epoch 49/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5371 - loss: 1.0565 - val_accuracy: 0.2417 - val_loss: 1.6729\n",
      "Epoch 50/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5352 - loss: 1.0782 - val_accuracy: 0.2292 - val_loss: 1.6901\n",
      "Epoch 51/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5504 - loss: 1.0555 - val_accuracy: 0.2354 - val_loss: 1.6779\n",
      "Epoch 52/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5392 - loss: 1.0693 - val_accuracy: 0.2375 - val_loss: 1.7001\n",
      "Epoch 53/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5267 - loss: 1.0667 - val_accuracy: 0.2396 - val_loss: 1.7047\n",
      "Epoch 54/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5557 - loss: 1.0386 - val_accuracy: 0.2458 - val_loss: 1.7159\n",
      "Epoch 55/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5542 - loss: 1.0355 - val_accuracy: 0.2375 - val_loss: 1.7274\n",
      "Epoch 56/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5482 - loss: 1.0491 - val_accuracy: 0.2583 - val_loss: 1.7271\n",
      "Epoch 57/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 1.0244 - val_accuracy: 0.2479 - val_loss: 1.7403\n",
      "Epoch 58/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5580 - loss: 1.0407 - val_accuracy: 0.2500 - val_loss: 1.7506\n",
      "Epoch 59/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5530 - loss: 1.0269 - val_accuracy: 0.2562 - val_loss: 1.7560\n",
      "Epoch 60/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5722 - loss: 0.9989 - val_accuracy: 0.2583 - val_loss: 1.7660\n",
      "Epoch 61/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 1.0206 - val_accuracy: 0.2438 - val_loss: 1.7591\n",
      "Epoch 62/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5608 - loss: 1.0292 - val_accuracy: 0.2417 - val_loss: 1.7844\n",
      "Epoch 63/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5651 - loss: 1.0121 - val_accuracy: 0.2333 - val_loss: 1.7855\n",
      "Epoch 64/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5735 - loss: 1.0129 - val_accuracy: 0.2396 - val_loss: 1.7939\n",
      "Epoch 65/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5564 - loss: 1.0033 - val_accuracy: 0.2313 - val_loss: 1.8034\n",
      "Epoch 66/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5728 - loss: 0.9987 - val_accuracy: 0.2333 - val_loss: 1.8123\n",
      "Epoch 67/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5709 - loss: 1.0013 - val_accuracy: 0.2417 - val_loss: 1.8189\n",
      "Epoch 68/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5704 - loss: 0.9882 - val_accuracy: 0.2417 - val_loss: 1.8204\n",
      "Epoch 69/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5575 - loss: 1.0127 - val_accuracy: 0.2479 - val_loss: 1.8176\n",
      "Epoch 70/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5783 - loss: 0.9930 - val_accuracy: 0.2354 - val_loss: 1.8329\n",
      "Epoch 71/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5717 - loss: 0.9838 - val_accuracy: 0.2417 - val_loss: 1.8386\n",
      "Epoch 72/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5815 - loss: 0.9671 - val_accuracy: 0.2479 - val_loss: 1.8481\n",
      "Epoch 73/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5797 - loss: 0.9670 - val_accuracy: 0.2417 - val_loss: 1.8566\n",
      "Epoch 74/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5851 - loss: 0.9681 - val_accuracy: 0.2354 - val_loss: 1.8775\n",
      "Epoch 75/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5877 - loss: 0.9601 - val_accuracy: 0.2417 - val_loss: 1.8726\n",
      "Epoch 76/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5874 - loss: 0.9830 - val_accuracy: 0.2438 - val_loss: 1.8804\n",
      "Epoch 77/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5743 - loss: 0.9820 - val_accuracy: 0.2396 - val_loss: 1.8883\n",
      "Epoch 78/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5956 - loss: 0.9791 - val_accuracy: 0.2417 - val_loss: 1.8951\n",
      "Epoch 79/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5826 - loss: 0.9817 - val_accuracy: 0.2417 - val_loss: 1.9025\n",
      "Epoch 80/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5858 - loss: 0.9653 - val_accuracy: 0.2458 - val_loss: 1.9094\n",
      "Epoch 81/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5935 - loss: 0.9566 - val_accuracy: 0.2521 - val_loss: 1.9110\n",
      "Epoch 82/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6117 - loss: 0.9440 - val_accuracy: 0.2417 - val_loss: 1.9285\n",
      "Epoch 83/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6029 - loss: 0.9596 - val_accuracy: 0.2479 - val_loss: 1.9263\n",
      "Epoch 84/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6093 - loss: 0.9410 - val_accuracy: 0.2479 - val_loss: 1.9255\n",
      "Epoch 85/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5946 - loss: 0.9624 - val_accuracy: 0.2375 - val_loss: 1.9424\n",
      "Epoch 86/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6123 - loss: 0.9395 - val_accuracy: 0.2354 - val_loss: 1.9559\n",
      "Epoch 87/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5990 - loss: 0.9409 - val_accuracy: 0.2375 - val_loss: 1.9625\n",
      "Epoch 88/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5967 - loss: 0.9311 - val_accuracy: 0.2438 - val_loss: 1.9626\n",
      "Epoch 89/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6036 - loss: 0.9352 - val_accuracy: 0.2438 - val_loss: 1.9687\n",
      "Epoch 90/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6188 - loss: 0.9381 - val_accuracy: 0.2521 - val_loss: 1.9662\n",
      "Epoch 91/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6153 - loss: 0.9320 - val_accuracy: 0.2500 - val_loss: 1.9642\n",
      "Epoch 92/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6016 - loss: 0.9370 - val_accuracy: 0.2500 - val_loss: 1.9869\n",
      "Epoch 93/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 0.9254 - val_accuracy: 0.2500 - val_loss: 1.9910\n",
      "Epoch 94/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6196 - loss: 0.9237 - val_accuracy: 0.2479 - val_loss: 1.9892\n",
      "Epoch 95/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6178 - loss: 0.9073 - val_accuracy: 0.2458 - val_loss: 2.0095\n",
      "Epoch 96/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6286 - loss: 0.9180 - val_accuracy: 0.2500 - val_loss: 2.0028\n",
      "Epoch 97/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6068 - loss: 0.9281 - val_accuracy: 0.2438 - val_loss: 2.0121\n",
      "Epoch 98/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6332 - loss: 0.8889 - val_accuracy: 0.2562 - val_loss: 2.0250\n",
      "Epoch 99/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6253 - loss: 0.9064 - val_accuracy: 0.2500 - val_loss: 2.0381\n",
      "Epoch 100/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6241 - loss: 0.8935 - val_accuracy: 0.2479 - val_loss: 2.0371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f4b1e42610>"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the neural network\n",
    "model = Sequential([\n",
    "    Dense(units=30, activation='relu'),\n",
    "    Dense(units=15, activation='relu'),\n",
    "    Dense(units=4, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "4ee9735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6280 - loss: 0.9109\n",
      "Loss:  1.122962236404419\n",
      "Accuracy:  0.5512499809265137\n"
     ]
    }
   ],
   "source": [
    "#training data evaluation \n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print(f'Loss: ', loss)\n",
    "print(f'Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "6a0c8793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2286 - loss: 2.0989  \n",
      "Loss:  2.0551364421844482\n",
      "Accuracy:  0.23499999940395355\n"
     ]
    }
   ],
   "source": [
    "#testing data evaluation \n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Loss: ', loss)\n",
    "print(f'Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc90a0",
   "metadata": {},
   "source": [
    "# Training the model on minimum features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = global_phonee_addiction_data[['Age', 'Gender', 'Daily_Screen_Time_Hours', 'Phone_Unlocks_Per_Day', 'Social_Media_Usage_Hours', 'Gaming_Usage_Hours', 'Streaming_Usage_Hours', 'Messaging_Usage_Hours', 'Work_Related_Usage_Hours','Sleep_Hours', 'Physical_Activity_Hours', 'Self_Reported_Addiction_Level', 'Mental_Health_Score', 'Depression_Score', 'Anxiety_Score', 'Stress_Level', 'Has_Screen_Time_Management_App']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e73d79a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Daily_Screen_Time_Hours</th>\n",
       "      <th>Phone_Unlocks_Per_Day</th>\n",
       "      <th>Social_Media_Usage_Hours</th>\n",
       "      <th>Gaming_Usage_Hours</th>\n",
       "      <th>Streaming_Usage_Hours</th>\n",
       "      <th>Messaging_Usage_Hours</th>\n",
       "      <th>Work_Related_Usage_Hours</th>\n",
       "      <th>Sleep_Hours</th>\n",
       "      <th>Physical_Activity_Hours</th>\n",
       "      <th>Self_Reported_Addiction_Level</th>\n",
       "      <th>Mental_Health_Score</th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Stress_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.81</td>\n",
       "      <td>75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.14</td>\n",
       "      <td>5.22</td>\n",
       "      <td>1.32</td>\n",
       "      <td>Low</td>\n",
       "      <td>61.47</td>\n",
       "      <td>80.80</td>\n",
       "      <td>23.72</td>\n",
       "      <td>95.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>9.05</td>\n",
       "      <td>61</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.44</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Severe</td>\n",
       "      <td>96.11</td>\n",
       "      <td>98.99</td>\n",
       "      <td>39.72</td>\n",
       "      <td>25.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Other</td>\n",
       "      <td>5.76</td>\n",
       "      <td>58</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.92</td>\n",
       "      <td>6.57</td>\n",
       "      <td>1.93</td>\n",
       "      <td>Severe</td>\n",
       "      <td>73.68</td>\n",
       "      <td>44.64</td>\n",
       "      <td>94.47</td>\n",
       "      <td>99.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Female</td>\n",
       "      <td>6.71</td>\n",
       "      <td>80</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.82</td>\n",
       "      <td>7.27</td>\n",
       "      <td>0.94</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>53.42</td>\n",
       "      <td>10.89</td>\n",
       "      <td>5.03</td>\n",
       "      <td>66.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>Other</td>\n",
       "      <td>6.31</td>\n",
       "      <td>136</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.76</td>\n",
       "      <td>5.43</td>\n",
       "      <td>1.04</td>\n",
       "      <td>High</td>\n",
       "      <td>67.01</td>\n",
       "      <td>37.54</td>\n",
       "      <td>17.29</td>\n",
       "      <td>14.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  ...  Anxiety_Score  Stress_Level\n",
       "0   32    Male  ...          23.72         95.80\n",
       "1   26    Male  ...          39.72         25.03\n",
       "2   70   Other  ...          94.47         99.54\n",
       "3   44  Female  ...           5.03         66.49\n",
       "4   46   Other  ...          17.29         14.72\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "846fa5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the categorical data\n",
    "gender_encoder = LabelEncoder()\n",
    "addiction_level_encoder = LabelEncoder()\n",
    "data['Gender'] = gender_encoder.fit_transform(data['Gender'])\n",
    "data['Self_Reported_Addiction_Level'] = addiction_level_encoder.fit_transform(data['Self_Reported_Addiction_Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "808bcc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 0\n",
      "Gender 0\n",
      "Daily_Screen_Time_Hours 9\n",
      "Phone_Unlocks_Per_Day 1\n",
      "Social_Media_Usage_Hours 70\n",
      "Gaming_Usage_Hours 213\n",
      "Streaming_Usage_Hours 67\n",
      "Messaging_Usage_Hours 2\n",
      "Work_Related_Usage_Hours 53\n",
      "Sleep_Hours 0\n",
      "Physical_Activity_Hours 80\n",
      "Self_Reported_Addiction_Level 0\n",
      "Mental_Health_Score 0\n",
      "Depression_Score 0\n",
      "Anxiety_Score 0\n",
      "Stress_Level 0\n"
     ]
    }
   ],
   "source": [
    "#checking for the negative values in the columns because hours cannot be in the negative. \n",
    "for column in data.columns:\n",
    "    print(column, len(data[column][data[column]<0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "b823467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the negative values to postive values\n",
    "data[data.columns] = data[data.columns].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "9c0d7c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                              0\n",
      "Gender                           0\n",
      "Daily_Screen_Time_Hours          0\n",
      "Phone_Unlocks_Per_Day            0\n",
      "Social_Media_Usage_Hours         0\n",
      "Gaming_Usage_Hours               0\n",
      "Streaming_Usage_Hours            0\n",
      "Messaging_Usage_Hours            0\n",
      "Work_Related_Usage_Hours         0\n",
      "Sleep_Hours                      0\n",
      "Physical_Activity_Hours          0\n",
      "Self_Reported_Addiction_Level    0\n",
      "Mental_Health_Score              0\n",
      "Depression_Score                 0\n",
      "Anxiety_Score                    0\n",
      "Stress_Level                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f6b4352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize each column\n",
    "# for column in data.columns:\n",
    "#     if(column == \"Gender\" or column == \"Self_Reported_Addiction_Level\"):\n",
    "#         continue\n",
    "#     else:\n",
    "#         print(data[column].skew())\n",
    "#         plt.figure(figsize=(6,4))\n",
    "#         sns.histplot(data[column], kde = True, bins = 30)\n",
    "#         plt.title(f\"Distribution of {column}\")\n",
    "#         plt.xlabel(column)\n",
    "#         plt.ylabel(\"frequency\")\n",
    "#         plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "722b14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data using the Standard Scalar\n",
    "x_scaler = StandardScaler()\n",
    "for column in data.columns:\n",
    "    if(column == \"Gender\" or column == \"Self_Reported_Addiction_Level\"):\n",
    "        continue\n",
    "    else:\n",
    "        data[column] = x_scaler.fit_transform(data[[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "7e3cb640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Daily_Screen_Time_Hours</th>\n",
       "      <th>Phone_Unlocks_Per_Day</th>\n",
       "      <th>Social_Media_Usage_Hours</th>\n",
       "      <th>Gaming_Usage_Hours</th>\n",
       "      <th>Streaming_Usage_Hours</th>\n",
       "      <th>Messaging_Usage_Hours</th>\n",
       "      <th>Work_Related_Usage_Hours</th>\n",
       "      <th>Sleep_Hours</th>\n",
       "      <th>Physical_Activity_Hours</th>\n",
       "      <th>Self_Reported_Addiction_Level</th>\n",
       "      <th>Mental_Health_Score</th>\n",
       "      <th>Depression_Score</th>\n",
       "      <th>Anxiety_Score</th>\n",
       "      <th>Stress_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>5.81</td>\n",
       "      <td>75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.14</td>\n",
       "      <td>5.22</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1</td>\n",
       "      <td>61.47</td>\n",
       "      <td>80.80</td>\n",
       "      <td>23.72</td>\n",
       "      <td>95.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>9.05</td>\n",
       "      <td>61</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.44</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3</td>\n",
       "      <td>96.11</td>\n",
       "      <td>98.99</td>\n",
       "      <td>39.72</td>\n",
       "      <td>25.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>5.76</td>\n",
       "      <td>58</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.92</td>\n",
       "      <td>6.57</td>\n",
       "      <td>1.93</td>\n",
       "      <td>3</td>\n",
       "      <td>73.68</td>\n",
       "      <td>44.64</td>\n",
       "      <td>94.47</td>\n",
       "      <td>99.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>6.71</td>\n",
       "      <td>80</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.82</td>\n",
       "      <td>7.27</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2</td>\n",
       "      <td>53.42</td>\n",
       "      <td>10.89</td>\n",
       "      <td>5.03</td>\n",
       "      <td>66.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>6.31</td>\n",
       "      <td>136</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.76</td>\n",
       "      <td>5.43</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0</td>\n",
       "      <td>67.01</td>\n",
       "      <td>37.54</td>\n",
       "      <td>17.29</td>\n",
       "      <td>14.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  ...  Anxiety_Score  Stress_Level\n",
       "0   32       1  ...          23.72         95.80\n",
       "1   26       1  ...          39.72         25.03\n",
       "2   70       2  ...          94.47         99.54\n",
       "3   44       0  ...           5.03         66.49\n",
       "4   46       2  ...          17.29         14.72\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the data after some preprocessing \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "6f903e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining x and y\n",
    "x = data.drop(columns=['Self_Reported_Addiction_Level'], axis=1)\n",
    "y = data['Self_Reported_Addiction_Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e063d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "592ba87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2715 - loss: 7.3864 - val_accuracy: 0.2542 - val_loss: 2.1345\n",
      "Epoch 2/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2591 - loss: 1.9302 - val_accuracy: 0.2562 - val_loss: 1.7439\n",
      "Epoch 3/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2521 - loss: 1.7120 - val_accuracy: 0.2438 - val_loss: 1.7454\n",
      "Epoch 4/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2728 - loss: 1.5901 - val_accuracy: 0.2396 - val_loss: 1.6016\n",
      "Epoch 5/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2805 - loss: 1.5582 - val_accuracy: 0.2250 - val_loss: 1.7361\n",
      "Epoch 6/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2688 - loss: 1.5772 - val_accuracy: 0.2333 - val_loss: 1.6261\n",
      "Epoch 7/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2788 - loss: 1.5075 - val_accuracy: 0.2562 - val_loss: 1.5844\n",
      "Epoch 8/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3018 - loss: 1.4592 - val_accuracy: 0.2104 - val_loss: 1.5369\n",
      "Epoch 9/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2884 - loss: 1.4463 - val_accuracy: 0.2146 - val_loss: 1.6078\n",
      "Epoch 10/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2959 - loss: 1.4658 - val_accuracy: 0.2396 - val_loss: 1.5710\n",
      "Epoch 11/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2982 - loss: 1.4247 - val_accuracy: 0.2542 - val_loss: 1.5399\n",
      "Epoch 12/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3133 - loss: 1.4020 - val_accuracy: 0.2083 - val_loss: 1.6762\n",
      "Epoch 13/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3143 - loss: 1.4438 - val_accuracy: 0.2042 - val_loss: 1.8255\n",
      "Epoch 14/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3101 - loss: 1.4349 - val_accuracy: 0.2583 - val_loss: 1.5595\n",
      "Epoch 15/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3144 - loss: 1.4109 - val_accuracy: 0.2188 - val_loss: 1.5991\n",
      "Epoch 16/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2762 - loss: 1.4733 - val_accuracy: 0.2438 - val_loss: 1.5182\n",
      "Epoch 17/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3131 - loss: 1.4404 - val_accuracy: 0.2229 - val_loss: 1.6314\n",
      "Epoch 18/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3136 - loss: 1.4082 - val_accuracy: 0.2500 - val_loss: 1.5416\n",
      "Epoch 19/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3332 - loss: 1.3850 - val_accuracy: 0.2354 - val_loss: 1.5060\n",
      "Epoch 20/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3508 - loss: 1.3741 - val_accuracy: 0.2438 - val_loss: 1.7134\n",
      "Epoch 21/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3280 - loss: 1.3855 - val_accuracy: 0.2354 - val_loss: 1.5717\n",
      "Epoch 22/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3223 - loss: 1.3700 - val_accuracy: 0.2313 - val_loss: 1.5419\n",
      "Epoch 23/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3040 - loss: 1.3937 - val_accuracy: 0.2417 - val_loss: 1.5404\n",
      "Epoch 24/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3670 - loss: 1.3457 - val_accuracy: 0.2583 - val_loss: 1.5377\n",
      "Epoch 25/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3372 - loss: 1.3866 - val_accuracy: 0.2521 - val_loss: 1.5443\n",
      "Epoch 26/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3406 - loss: 1.3796 - val_accuracy: 0.2271 - val_loss: 1.6213\n",
      "Epoch 27/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3414 - loss: 1.3587 - val_accuracy: 0.2229 - val_loss: 1.5387\n",
      "Epoch 28/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3390 - loss: 1.3682 - val_accuracy: 0.2313 - val_loss: 1.7484\n",
      "Epoch 29/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3661 - loss: 1.3861 - val_accuracy: 0.2583 - val_loss: 1.6380\n",
      "Epoch 30/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3396 - loss: 1.3726 - val_accuracy: 0.2208 - val_loss: 1.6035\n",
      "Epoch 31/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3746 - loss: 1.3387 - val_accuracy: 0.2375 - val_loss: 1.5477\n",
      "Epoch 32/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3360 - loss: 1.3950 - val_accuracy: 0.2417 - val_loss: 1.5109\n",
      "Epoch 33/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3490 - loss: 1.3480 - val_accuracy: 0.2438 - val_loss: 1.5070\n",
      "Epoch 34/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3548 - loss: 1.3384 - val_accuracy: 0.2417 - val_loss: 1.5079\n",
      "Epoch 35/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3710 - loss: 1.3438 - val_accuracy: 0.2208 - val_loss: 1.5596\n",
      "Epoch 36/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3455 - loss: 1.3573 - val_accuracy: 0.2417 - val_loss: 1.6157\n",
      "Epoch 37/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3630 - loss: 1.3326 - val_accuracy: 0.2625 - val_loss: 1.6404\n",
      "Epoch 38/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3463 - loss: 1.3593 - val_accuracy: 0.2375 - val_loss: 1.5296\n",
      "Epoch 39/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3840 - loss: 1.3253 - val_accuracy: 0.2396 - val_loss: 1.6361\n",
      "Epoch 40/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3718 - loss: 1.3122 - val_accuracy: 0.2208 - val_loss: 1.5418\n",
      "Epoch 41/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3584 - loss: 1.3307 - val_accuracy: 0.2313 - val_loss: 1.5219\n",
      "Epoch 42/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3990 - loss: 1.3120 - val_accuracy: 0.2333 - val_loss: 1.5498\n",
      "Epoch 43/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3780 - loss: 1.3091 - val_accuracy: 0.2396 - val_loss: 1.5281\n",
      "Epoch 44/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3878 - loss: 1.3041 - val_accuracy: 0.2375 - val_loss: 1.5070\n",
      "Epoch 45/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3336 - loss: 1.3412 - val_accuracy: 0.2479 - val_loss: 1.5180\n",
      "Epoch 46/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3808 - loss: 1.3129 - val_accuracy: 0.2417 - val_loss: 1.5350\n",
      "Epoch 47/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3660 - loss: 1.3627 - val_accuracy: 0.2458 - val_loss: 1.5591\n",
      "Epoch 48/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3766 - loss: 1.3180 - val_accuracy: 0.2417 - val_loss: 1.6237\n",
      "Epoch 49/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3386 - loss: 1.3634 - val_accuracy: 0.2333 - val_loss: 1.5666\n",
      "Epoch 50/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3885 - loss: 1.3016 - val_accuracy: 0.2104 - val_loss: 1.6843\n",
      "Epoch 51/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3536 - loss: 1.3431 - val_accuracy: 0.2313 - val_loss: 1.5459\n",
      "Epoch 52/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3783 - loss: 1.3024 - val_accuracy: 0.2229 - val_loss: 1.5918\n",
      "Epoch 53/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3689 - loss: 1.3257 - val_accuracy: 0.2167 - val_loss: 1.5254\n",
      "Epoch 54/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3705 - loss: 1.3057 - val_accuracy: 0.2562 - val_loss: 1.5695\n",
      "Epoch 55/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3585 - loss: 1.3187 - val_accuracy: 0.2521 - val_loss: 1.5935\n",
      "Epoch 56/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3873 - loss: 1.3295 - val_accuracy: 0.2438 - val_loss: 1.5647\n",
      "Epoch 57/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3656 - loss: 1.3174 - val_accuracy: 0.2396 - val_loss: 1.5607\n",
      "Epoch 58/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3898 - loss: 1.2930 - val_accuracy: 0.2479 - val_loss: 1.5852\n",
      "Epoch 59/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3682 - loss: 1.3150 - val_accuracy: 0.2250 - val_loss: 1.5486\n",
      "Epoch 60/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3683 - loss: 1.3348 - val_accuracy: 0.2229 - val_loss: 1.5265\n",
      "Epoch 61/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3935 - loss: 1.2828 - val_accuracy: 0.2333 - val_loss: 1.5300\n",
      "Epoch 62/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3726 - loss: 1.2954 - val_accuracy: 0.2417 - val_loss: 1.5559\n",
      "Epoch 63/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3714 - loss: 1.2980 - val_accuracy: 0.2250 - val_loss: 1.6620\n",
      "Epoch 64/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3690 - loss: 1.3190 - val_accuracy: 0.2354 - val_loss: 1.6121\n",
      "Epoch 65/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3935 - loss: 1.2776 - val_accuracy: 0.2396 - val_loss: 1.5866\n",
      "Epoch 66/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3948 - loss: 1.2714 - val_accuracy: 0.2542 - val_loss: 1.5821\n",
      "Epoch 67/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3800 - loss: 1.3048 - val_accuracy: 0.2167 - val_loss: 1.5518\n",
      "Epoch 68/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3754 - loss: 1.2975 - val_accuracy: 0.2271 - val_loss: 1.5690\n",
      "Epoch 69/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3773 - loss: 1.2803 - val_accuracy: 0.2417 - val_loss: 1.5628\n",
      "Epoch 70/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3964 - loss: 1.2719 - val_accuracy: 0.2208 - val_loss: 1.5453\n",
      "Epoch 71/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3919 - loss: 1.2756 - val_accuracy: 0.2625 - val_loss: 1.5809\n",
      "Epoch 72/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3974 - loss: 1.3029 - val_accuracy: 0.2375 - val_loss: 1.5260\n",
      "Epoch 73/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4069 - loss: 1.2913 - val_accuracy: 0.2500 - val_loss: 1.5517\n",
      "Epoch 74/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4182 - loss: 1.2605 - val_accuracy: 0.2271 - val_loss: 1.7392\n",
      "Epoch 75/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3574 - loss: 1.3177 - val_accuracy: 0.2542 - val_loss: 1.6707\n",
      "Epoch 76/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3856 - loss: 1.3035 - val_accuracy: 0.2250 - val_loss: 1.5857\n",
      "Epoch 77/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4164 - loss: 1.2621 - val_accuracy: 0.2375 - val_loss: 1.5993\n",
      "Epoch 78/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4056 - loss: 1.2524 - val_accuracy: 0.2542 - val_loss: 1.5482\n",
      "Epoch 79/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4122 - loss: 1.2439 - val_accuracy: 0.2208 - val_loss: 1.5845\n",
      "Epoch 80/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3894 - loss: 1.2826 - val_accuracy: 0.2396 - val_loss: 1.5319\n",
      "Epoch 81/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3973 - loss: 1.2957 - val_accuracy: 0.2229 - val_loss: 1.5821\n",
      "Epoch 82/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3834 - loss: 1.3045 - val_accuracy: 0.2333 - val_loss: 1.5910\n",
      "Epoch 83/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3956 - loss: 1.2991 - val_accuracy: 0.2250 - val_loss: 1.6040\n",
      "Epoch 84/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4062 - loss: 1.2602 - val_accuracy: 0.2354 - val_loss: 1.5902\n",
      "Epoch 85/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3970 - loss: 1.2800 - val_accuracy: 0.2438 - val_loss: 1.5564\n",
      "Epoch 86/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3933 - loss: 1.2896 - val_accuracy: 0.2854 - val_loss: 1.5656\n",
      "Epoch 87/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4216 - loss: 1.2409 - val_accuracy: 0.2333 - val_loss: 1.5620\n",
      "Epoch 88/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4239 - loss: 1.2521 - val_accuracy: 0.2271 - val_loss: 1.5470\n",
      "Epoch 89/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4124 - loss: 1.2739 - val_accuracy: 0.2521 - val_loss: 1.6269\n",
      "Epoch 90/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4182 - loss: 1.2436 - val_accuracy: 0.2333 - val_loss: 1.5877\n",
      "Epoch 91/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3859 - loss: 1.2733 - val_accuracy: 0.2646 - val_loss: 1.5529\n",
      "Epoch 92/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4046 - loss: 1.2616 - val_accuracy: 0.2250 - val_loss: 1.5766\n",
      "Epoch 93/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3949 - loss: 1.2672 - val_accuracy: 0.2271 - val_loss: 1.7283\n",
      "Epoch 94/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4099 - loss: 1.2967 - val_accuracy: 0.2208 - val_loss: 1.6713\n",
      "Epoch 95/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3956 - loss: 1.2715 - val_accuracy: 0.2542 - val_loss: 1.6428\n",
      "Epoch 96/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4059 - loss: 1.2603 - val_accuracy: 0.2229 - val_loss: 1.6774\n",
      "Epoch 97/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3876 - loss: 1.3062 - val_accuracy: 0.2292 - val_loss: 1.5823\n",
      "Epoch 98/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4133 - loss: 1.2430 - val_accuracy: 0.2250 - val_loss: 1.6201\n",
      "Epoch 99/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4315 - loss: 1.2415 - val_accuracy: 0.2562 - val_loss: 1.6358\n",
      "Epoch 100/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3974 - loss: 1.2717 - val_accuracy: 0.2542 - val_loss: 1.5775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f4862bf010>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model = Sequential([\n",
    "    Dense(units = 60, activation='relu'),\n",
    "    Dense(units = 30, activation='relu'),\n",
    "    Dense(units=4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss= SparseCategoricalCrossentropy, metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs = 100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9f49ae87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7791 - loss: 0.6784\n",
      "loss:  0.9819880127906799\n",
      "accuracy:  0.6745833158493042\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model on training dataset\n",
    "train_loss, train_accuracy = model.evaluate(x_train, y_train)\n",
    "print(f\"loss: \",train_loss)\n",
    "print(f\"accuracy: \",train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e6468927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2653 - loss: 2.2767  \n",
      "loss:  2.3197386264801025\n",
      "accuracy:  0.2433333396911621\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model on testing dataset\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"loss: \",test_loss)\n",
    "print(f\"accuracy: \",test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
